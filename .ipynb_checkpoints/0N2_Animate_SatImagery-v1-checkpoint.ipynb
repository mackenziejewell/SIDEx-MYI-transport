{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0N2_Animate_SatImagery\n",
    "\n",
    "---\n",
    "Read in and plot thermal infrared image(s) from MODIS and VIIRS level1b radiances. \n",
    "\n",
    "Overlay ERA5 atmospheric reanalysis surface atmospheric conditions (doi: 10.24381/cds.adbb2d47) and SIDEx buoy positions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from common_imports import *\n",
    "\n",
    "from LIB_plot_sat import *\n",
    "from LIB_plot_VIIRS import *\n",
    "from LIB_plot_MODIS import *\n",
    "\n",
    "import matplotlib.path as mpath\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "from pyproj import Geod\n",
    "g = Geod(ellps='WGS84')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import level1b MODIS files (HDF and GEO)\n",
    "Download from: https://ladsweb.modaps.eosdis.nasa.gov/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search within main folder: /Users/mackenziejewell/Desktop/filenames/\n",
      "Pair 0\n",
      "------\n",
      "2021-03-01 05:05:00\n",
      "2021-03-01 05:10:00\n",
      "\n",
      "Pair 1\n",
      "------\n",
      "2021-03-01 06:45:00\n",
      "\n",
      "Pair 2\n",
      "------\n",
      "2021-03-02 05:50:00\n",
      "\n",
      "Pair 3\n",
      "------\n",
      "2021-03-02 07:25:00\n",
      "2021-03-02 07:30:00\n",
      "\n",
      "Pair 4\n",
      "------\n",
      "2021-03-03 04:55:00\n",
      "\n",
      "Pair 5\n",
      "------\n",
      "2021-03-03 06:30:00\n",
      "2021-03-03 06:35:00\n",
      "\n",
      "Pair 6\n",
      "------\n",
      "2021-03-04 05:35:00\n",
      "2021-03-04 05:40:00\n",
      "\n",
      "Pair 7\n",
      "------\n",
      "2021-03-04 07:15:00\n",
      "\n",
      "Pair 8\n",
      "------\n",
      "2021-03-05 04:40:00\n",
      "2021-03-05 04:45:00\n",
      "\n",
      "Pair 9\n",
      "------\n",
      "2021-03-05 06:20:00\n",
      "\n",
      "Pair 10\n",
      "------\n",
      "2021-03-06 05:25:00\n",
      "\n",
      "Pair 11\n",
      "------\n",
      "2021-03-06 07:00:00\n",
      "2021-03-06 07:05:00\n",
      "\n",
      "Pair 12\n",
      "------\n",
      "2021-03-07 04:30:00\n",
      "\n",
      "Pair 13\n",
      "------\n",
      "2021-03-07 06:05:00\n",
      "2021-03-07 06:10:00\n",
      "\n",
      "Pair 14\n",
      "------\n",
      "2021-03-08 05:10:00\n",
      "2021-03-08 05:15:00\n",
      "\n",
      "Pair 15\n",
      "------\n",
      "2021-03-08 06:50:00\n",
      "2021-03-08 06:55:00\n",
      "\n",
      "Pair 16\n",
      "------\n",
      "2021-03-09 05:55:00\n",
      "2021-03-09 06:00:00\n",
      "\n",
      "Pair 17\n",
      "------\n",
      "2021-03-09 07:30:00\n",
      "2021-03-09 07:35:00\n",
      "\n",
      "Pair 18\n",
      "------\n",
      "2021-03-10 05:00:00\n",
      "2021-03-10 05:05:00\n",
      "\n",
      "Pair 19\n",
      "------\n",
      "2021-03-10 06:35:00\n",
      "2021-03-10 06:40:00\n",
      "\n",
      "Pair 20\n",
      "------\n",
      "2021-03-11 05:40:00\n",
      "2021-03-11 05:45:00\n",
      "\n",
      "Pair 21\n",
      "------\n",
      "2021-03-11 07:20:00\n",
      "2021-03-11 07:25:00\n",
      "\n",
      "Pair 22\n",
      "------\n",
      "2021-03-12 04:45:00\n",
      "2021-03-12 04:50:00\n",
      "\n",
      "Pair 23\n",
      "------\n",
      "2021-03-12 06:25:00\n",
      "2021-03-12 06:30:00\n",
      "\n",
      "Pair 24\n",
      "------\n",
      "2021-03-13 05:30:00\n",
      "2021-03-13 05:35:00\n",
      "\n",
      "Pair 25\n",
      "------\n",
      "2021-03-13 07:10:00\n",
      "\n",
      "Pair 26\n",
      "------\n",
      "2021-03-14 04:35:00\n",
      "2021-03-14 04:40:00\n",
      "\n",
      "Pair 27\n",
      "------\n",
      "2021-03-14 06:10:00\n",
      "2021-03-14 06:15:00\n",
      "\n",
      "Pair 28\n",
      "------\n",
      "2021-03-15 05:15:00\n",
      "2021-03-15 05:20:00\n",
      "\n",
      "Pair 29\n",
      "------\n",
      "2021-03-15 06:55:00\n",
      "2021-03-15 07:00:00\n",
      "\n",
      "Pair 30\n",
      "------\n",
      "2021-03-16 04:20:00\n",
      "2021-03-16 04:25:00\n",
      "\n",
      "Pair 31\n",
      "------\n",
      "2021-03-16 06:00:00\n",
      "2021-03-16 06:05:00\n",
      "\n",
      "Pair 32\n",
      "------\n",
      "2021-03-17 05:05:00\n",
      "2021-03-17 05:10:00\n",
      "\n",
      "Pair 33\n",
      "------\n",
      "2021-03-17 06:45:00\n",
      "2021-03-17 06:50:00\n",
      "\n",
      "Pair 34\n",
      "------\n",
      "2021-03-18 04:10:00\n",
      "2021-03-18 04:15:00\n",
      "\n",
      "Pair 35\n",
      "------\n",
      "2021-03-18 05:45:00\n",
      "2021-03-18 05:50:00\n",
      "\n",
      "Pair 36\n",
      "------\n",
      "2021-03-19 04:50:00\n",
      "2021-03-19 04:55:00\n",
      "\n",
      "Pair 37\n",
      "------\n",
      "2021-03-19 06:30:00\n",
      "2021-03-19 06:35:00\n",
      "\n",
      "Pair 38\n",
      "------\n",
      "2021-03-20 05:35:00\n",
      "2021-03-20 05:40:00\n",
      "\n",
      "Pair 39\n",
      "------\n",
      "2021-03-20 07:15:00\n",
      "2021-03-20 07:20:00\n",
      "\n",
      "Pair 40\n",
      "------\n",
      "2021-03-21 04:40:00\n",
      "2021-03-21 04:45:00\n",
      "\n",
      "Pair 41\n",
      "------\n",
      "2021-03-21 06:20:00\n",
      "2021-03-21 06:25:00\n",
      "\n",
      "Pair 42\n",
      "------\n",
      "2021-03-22 05:25:00\n",
      "2021-03-22 05:30:00\n",
      "\n",
      "Pair 43\n",
      "------\n",
      "2021-03-22 07:00:00\n",
      "2021-03-22 07:05:00\n",
      "\n",
      "Pair 44\n",
      "------\n",
      "2021-03-23 04:30:00\n",
      "\n",
      "Pair 45\n",
      "------\n",
      "2021-03-23 06:05:00\n",
      "2021-03-23 06:10:00\n",
      "\n",
      "Pair 46\n",
      "------\n",
      "2021-03-24 05:10:00\n",
      "2021-03-24 05:15:00\n",
      "\n",
      "Pair 47\n",
      "------\n",
      "2021-03-24 06:50:00\n",
      "2021-03-24 06:55:00\n",
      "\n",
      "Pair 48\n",
      "------\n",
      "2021-03-25 04:15:00\n",
      "2021-03-25 04:20:00\n",
      "\n",
      "Pair 49\n",
      "------\n",
      "2021-03-25 05:55:00\n",
      "2021-03-25 06:00:00\n",
      "\n",
      "Pair 50\n",
      "------\n",
      "2021-03-26 05:00:00\n",
      "2021-03-26 05:05:00\n",
      "\n",
      "Pair 51\n",
      "------\n",
      "2021-03-26 06:35:00\n",
      "2021-03-26 06:40:00\n",
      "\n",
      "Pair 52\n",
      "------\n",
      "2021-03-27 04:05:00\n",
      "2021-03-27 04:10:00\n",
      "\n",
      "Pair 53\n",
      "------\n",
      "2021-03-27 07:20:00\n",
      "2021-03-27 07:25:00\n",
      "\n",
      "Pair 54\n",
      "------\n",
      "2021-03-28 04:45:00\n",
      "2021-03-28 04:50:00\n",
      "\n",
      "Pair 55\n",
      "------\n",
      "2021-03-28 06:25:00\n",
      "2021-03-28 06:30:00\n",
      "\n",
      "Pair 56\n",
      "------\n",
      "2021-03-29 03:50:00\n",
      "2021-03-29 03:55:00\n",
      "\n",
      "Pair 57\n",
      "------\n",
      "2021-03-29 07:05:00\n",
      "2021-03-29 07:10:00\n",
      "\n",
      "Pair 58\n",
      "------\n",
      "2021-03-30 04:35:00\n",
      "2021-03-30 04:40:00\n",
      "\n",
      "Pair 59\n",
      "------\n",
      "2021-03-30 06:10:00\n",
      "2021-03-30 06:15:00\n",
      "\n",
      "Pair 60\n",
      "------\n",
      "2021-03-31 03:40:00\n",
      "2021-03-31 03:45:00\n",
      "\n",
      "Pair 61\n",
      "------\n",
      "2021-03-31 06:55:00\n",
      "2021-03-31 07:00:00\n",
      "\n",
      "Pair 62\n",
      "------\n",
      "2021-04-01 04:20:00\n",
      "2021-04-01 04:25:00\n",
      "\n",
      "Pair 63\n",
      "------\n",
      "2021-04-01 07:40:00\n",
      "2021-04-01 07:45:00\n",
      "\n",
      "Pair 64\n",
      "------\n",
      "2021-04-02 05:05:00\n",
      "2021-04-02 05:10:00\n",
      "\n",
      "Pair 65\n",
      "------\n",
      "2021-04-02 06:45:00\n",
      "2021-04-02 06:50:00\n",
      "\n",
      "Pair 66\n",
      "------\n",
      "2021-04-03 05:45:00\n",
      "2021-04-03 05:50:00\n",
      "\n",
      "Pair 67\n",
      "------\n",
      "2021-04-03 07:25:00\n",
      "2021-04-03 07:30:00\n",
      "\n",
      "Pair 68\n",
      "------\n",
      "2021-04-04 04:50:00\n",
      "2021-04-04 04:55:00\n",
      "\n",
      "Pair 69\n",
      "------\n",
      "2021-04-04 06:30:00\n",
      "2021-04-04 06:35:00\n",
      "\n",
      "Pair 70\n",
      "------\n",
      "2021-04-05 04:00:00\n",
      "\n",
      "Pair 71\n",
      "------\n",
      "2021-04-05 07:15:00\n",
      "2021-04-05 07:20:00\n",
      "\n",
      "Pair 72\n",
      "------\n",
      "2021-04-06 04:40:00\n",
      "2021-04-06 04:45:00\n",
      "\n",
      "Pair 73\n",
      "------\n",
      "2021-04-06 06:20:00\n",
      "2021-04-06 06:25:00\n",
      "\n",
      "Pair 74\n",
      "------\n",
      "2021-04-07 05:20:00\n",
      "2021-04-07 05:25:00\n",
      "\n",
      "Pair 75\n",
      "------\n",
      "2021-04-07 07:00:00\n",
      "2021-04-07 07:05:00\n",
      "\n",
      "Pair 76\n",
      "------\n",
      "2021-04-08 04:25:00\n",
      "2021-04-08 04:30:00\n",
      "\n",
      "Pair 77\n",
      "------\n",
      "2021-04-08 06:05:00\n",
      "2021-04-08 06:10:00\n",
      "\n",
      "Pair 78\n",
      "------\n",
      "2021-04-09 05:10:00\n",
      "2021-04-09 05:15:00\n",
      "\n",
      "Pair 79\n",
      "------\n",
      "2021-04-09 06:50:00\n",
      "2021-04-09 06:55:00\n",
      "\n",
      "Pair 80\n",
      "------\n",
      "2021-04-10 04:15:00\n",
      "2021-04-10 04:20:00\n",
      "\n",
      "Pair 81\n",
      "------\n",
      "2021-04-10 07:30:00\n",
      "2021-04-10 07:35:00\n",
      "\n",
      "Pair 82\n",
      "------\n",
      "2021-04-11 04:55:00\n",
      "2021-04-11 05:00:00\n",
      "\n",
      "Pair 83\n",
      "------\n",
      "2021-04-11 06:35:00\n",
      "2021-04-11 06:40:00\n",
      "\n",
      "Pair 84\n",
      "------\n",
      "2021-04-12 05:40:00\n",
      "2021-04-12 05:45:00\n",
      "\n",
      "Pair 85\n",
      "------\n",
      "2021-04-12 07:20:00\n",
      "2021-04-12 07:25:00\n",
      "\n",
      "Pair 86\n",
      "------\n",
      "2021-04-13 04:45:00\n",
      "2021-04-13 04:50:00\n",
      "\n",
      "Pair 87\n",
      "------\n",
      "2021-04-13 06:25:00\n",
      "2021-04-13 06:30:00\n",
      "\n",
      "Pair 88\n",
      "------\n",
      "2021-04-14 05:30:00\n",
      "2021-04-14 05:35:00\n",
      "\n",
      "Pair 89\n",
      "------\n",
      "2021-04-14 07:05:00\n",
      "2021-04-14 07:10:00\n",
      "\n",
      "Pair 90\n",
      "------\n",
      "2021-04-15 04:35:00\n",
      "2021-04-15 04:40:00\n",
      "\n",
      "Pair 91\n",
      "------\n",
      "2021-04-15 06:10:00\n",
      "2021-04-15 06:15:00\n",
      "\n",
      "Pair 92\n",
      "------\n",
      "2021-04-16 03:40:00\n",
      "2021-04-16 03:45:00\n",
      "\n",
      "Pair 93\n",
      "------\n",
      "2021-04-16 06:55:00\n",
      "2021-04-16 07:00:00\n",
      "\n",
      "Pair 94\n",
      "------\n",
      "2021-04-17 04:20:00\n",
      "2021-04-17 04:25:00\n",
      "\n",
      "Pair 95\n",
      "------\n",
      "2021-04-17 06:00:00\n",
      "2021-04-17 06:05:00\n",
      "\n",
      "Pair 96\n",
      "------\n",
      "2021-04-18 05:05:00\n",
      "2021-04-18 05:10:00\n",
      "\n",
      "Pair 97\n",
      "------\n",
      "2021-04-18 06:40:00\n",
      "2021-04-18 06:45:00\n",
      "\n",
      "Pair 98\n",
      "------\n",
      "2021-04-19 04:10:00\n",
      "2021-04-19 04:15:00\n",
      "\n",
      "Pair 99\n",
      "------\n",
      "2021-04-19 07:25:00\n",
      "2021-04-19 07:30:00\n",
      "\n",
      "Pair 100\n",
      "------\n",
      "2021-04-20 04:50:00\n",
      "2021-04-20 04:55:00\n",
      "\n",
      "Pair 101\n",
      "------\n",
      "2021-04-20 06:30:00\n",
      "2021-04-20 06:35:00\n",
      "\n",
      "Pair 102\n",
      "------\n",
      "2021-04-21 03:55:00\n",
      "2021-04-21 04:00:00\n",
      "\n",
      "Pair 103\n",
      "------\n",
      "2021-04-21 07:15:00\n",
      "2021-04-21 07:20:00\n",
      "\n",
      "Pair 104\n",
      "------\n",
      "2021-04-22 04:40:00\n",
      "2021-04-22 04:45:00\n",
      "\n",
      "Pair 105\n",
      "------\n",
      "2021-04-22 06:20:00\n",
      "2021-04-22 06:25:00\n",
      "\n",
      "Pair 106\n",
      "------\n",
      "2021-04-23 05:20:00\n",
      "2021-04-23 05:25:00\n",
      "\n",
      "Pair 107\n",
      "------\n",
      "2021-04-23 07:00:00\n",
      "2021-04-23 07:05:00\n",
      "\n",
      "Pair 108\n",
      "------\n",
      "2021-04-24 04:25:00\n",
      "2021-04-24 04:30:00\n",
      "\n",
      "Pair 109\n",
      "------\n",
      "2021-04-24 06:05:00\n",
      "2021-04-24 06:10:00\n",
      "\n",
      "Pair 110\n",
      "------\n",
      "2021-04-25 05:10:00\n",
      "2021-04-25 05:15:00\n",
      "\n",
      "Pair 111\n",
      "------\n",
      "2021-04-25 06:50:00\n",
      "2021-04-25 06:55:00\n",
      "\n",
      "Pair 112\n",
      "------\n",
      "2021-04-26 04:15:00\n",
      "2021-04-26 04:20:00\n",
      "\n",
      "Pair 113\n",
      "------\n",
      "2021-04-26 05:55:00\n",
      "2021-04-26 06:00:00\n",
      "\n",
      "Pair 114\n",
      "------\n",
      "2021-04-27 04:55:00\n",
      "2021-04-27 05:00:00\n",
      "\n",
      "Pair 115\n",
      "------\n",
      "2021-04-27 06:35:00\n",
      "2021-04-27 06:40:00\n",
      "\n",
      "Pair 116\n",
      "------\n",
      "2021-04-28 04:05:00\n",
      "\n",
      "Pair 117\n",
      "------\n",
      "2021-04-28 07:20:00\n",
      "2021-04-28 07:25:00\n",
      "\n",
      "Pair 118\n",
      "------\n",
      "2021-04-29 04:45:00\n",
      "2021-04-29 04:50:00\n",
      "\n",
      "Pair 119\n",
      "------\n",
      "2021-04-29 06:25:00\n",
      "2021-04-29 06:30:00\n",
      "\n",
      "Pair 120\n",
      "------\n",
      "2021-04-30 03:50:00\n",
      "2021-04-30 03:55:00\n",
      "\n",
      "Pair 121\n",
      "------\n",
      "2021-04-30 07:05:00\n",
      "2021-04-30 07:10:00\n",
      "\n",
      "Pair 122\n",
      "------\n",
      "2021-05-01 04:35:00\n",
      "2021-05-01 04:40:00\n",
      "\n",
      "Pair 123\n",
      "------\n",
      "2021-05-01 06:10:00\n",
      "2021-05-01 06:15:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set paths for location of level1b hdf and geolocation files\n",
    "# set provided folder type as path to folder and other as []\n",
    "MainFolder = [] \n",
    "SingleFolder = []\n",
    "#==============================================================\n",
    "MainFolder = '/Users/mackenziejewell/Desktop/filenames/'\n",
    "# SingleFolder = '/Users/mackenziejewell/Desktop/temp/VIIRS/'\n",
    "# SingleFolder = '/Users/mackenziejewell/Desktop/filenames/plot/2021085/'\n",
    "#==============================================================\n",
    "\n",
    "\n",
    "#==============================================================\n",
    "# sensor = 'VIIRS'\n",
    "sensor = 'MODIS'\n",
    "#==============================================================\n",
    "\n",
    "if str(sensor) == 'VIIRS':\n",
    "    satellite_labels = [('VNP03MOD','VNP02MOD'), ('VJ103MOD','VJ102MOD')]\n",
    "elif str(sensor) == 'MODIS':\n",
    "    satellite_labels = [('MOD03','MOD021KM'), ('MYD03','MYD021KM')]\n",
    "\n",
    "Image_Meta_paired = pair_images_meta(MainFolder = MainFolder, SingleFolder = SingleFolder, \n",
    "                                     sensor = sensor, satellite_labels = satellite_labels,\n",
    "                                     min_geofile_sizeMB = 28, min_imfile_sizeMB = 50, max_diff_minutes = 20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify which pairs of images to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which pairs of images to plot\n",
    "# either 'All' or index(es) of images to plot (e.g. [1,3,6])\n",
    "#==============================================================\n",
    "# RunPair = [0] \n",
    "# RunPair = np.arange(19, 63) \n",
    "RunPair = 'All'\n",
    "#=============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECMWF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name and directory for ECMWF atmospheric data (nc file type)\n",
    "# or set = None if you don't want to include\n",
    "#==============================================================\n",
    "# ECMWF = None\n",
    "ECMWF = '/Volumes/Jewell_EasyStore/ECMWF/annual/hourly/ERA5_2021.nc'\n",
    "#==============================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buoy coordinate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set list of path+name of csv files containing coordinates\n",
    "# or set = None if not adding buoy coordinates\n",
    "#==============================================================\n",
    "# csv_directory = None\n",
    "buoy_file = './data/BuoyCoordinates_cln_v0.nc'\n",
    "#==============================================================\n",
    "ds = xr.open_dataset(buoy_file)\n",
    "ds.close()\n",
    "buoy_time = pd.to_datetime(ds.time.values)\n",
    "\n",
    "\n",
    "from LIB_SIDExbuoy import open_buoy_data, calc_velocity, calculate_velocity\n",
    "\n",
    "def grab_buoy_velocities(ImageDate, ds, buoy_time):\n",
    "    \n",
    "    # find index nearest to date\n",
    "    nearest_ind = np.argmin(np.abs((buoy_time - ImageDate)))\n",
    "    time_slice = buoy_time[nearest_ind-1:nearest_ind+2]\n",
    "\n",
    "    # grab all buoy coords and velocities\n",
    "    all_buoys = ds.buoyID.values\n",
    "    buoy_lons = np.array([])\n",
    "    buoy_lats = np.array([])\n",
    "    buoy_u = np.array([])\n",
    "    buoy_v = np.array([])\n",
    "    \n",
    "    for buoy in all_buoys:\n",
    "    \n",
    "        crop_time = ds.sel(time=time_slice).sel(buoyID=buoy)\n",
    "\n",
    "        # calc velocity\n",
    "        out = calculate_velocity(lons = crop_time.longitude.values, lats = crop_time.latitude.values, \n",
    "                                 times = pd.to_datetime(crop_time.time.values), method = 'centered')\n",
    "        u, v, sp, time, lat, lon, dx, dy, di, az, dt = out\n",
    "\n",
    "        if len(u) == 0:\n",
    "            buoy_lons = np.append(buoy_lons, np.nan)\n",
    "            buoy_lats = np.append(buoy_lats, np.nan)\n",
    "            buoy_u = np.append(buoy_u, np.nan)\n",
    "            buoy_v = np.append(buoy_v, np.nan)\n",
    "\n",
    "        else:\n",
    "            buoy_lons = np.append(buoy_lons, lon)\n",
    "            buoy_lats = np.append(buoy_lats, lat)\n",
    "            buoy_u = np.append(buoy_u, u.magnitude)\n",
    "            buoy_v = np.append(buoy_v, v.magnitude)\n",
    "\n",
    "    return buoy_lons, buoy_lats, buoy_u, buoy_v\n",
    "\n",
    "\n",
    "# function to interpolate ERA5 winds local to each buoy\n",
    "\n",
    "import bisect\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "def interpolate_uv(ds = [], interp_lon = 100, interp_lat = 70, \n",
    "                   variables = ['u10', 'v10'],\n",
    "                   buffer_lon = 1, buffer_lat = 1):\n",
    "\n",
    "    \"\"\"Interpolate data variables over specific points on lat/lon grid.\n",
    "    This uses scipy RegularGridInterpolator so does not take into account true distances \n",
    "    between regularly gridded geo data points, but should be close enough!\n",
    "    \n",
    "    ds: xarray dataset with 'longitude' and 'latitude' coordinates, and variables\n",
    "    interp_lon: longitude to interpolate ds data variables at\n",
    "    interp_lat: latitude to interpolate ds data variables at\n",
    "    variables: (Lx1) list of data variable names in ds to interpolate\n",
    "    \n",
    "    OUTPUT:\n",
    "    - values: (Lx1) list of inteprolated values from data variables\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # create buoy coordinate data \n",
    "    interp = {}\n",
    "    interp['latitude'] = interp_lat\n",
    "    interp['longitude'] = interp_lon\n",
    "\n",
    "    # reverse coordinates if not ascending\n",
    "    if ds['latitude'][0] > ds['latitude'][1]:\n",
    "        ds = ds.sortby('latitude', ascending=True)   \n",
    "    if ds['longitude'][0] > ds['longitude'][1]:\n",
    "        ds = ds.sortby('longitude', ascending=True)   \n",
    "\n",
    "    # find coordinates within buffer of desired coords\n",
    "    lon_ind = bisect.bisect_left(ds['longitude'], interp['longitude'])\n",
    "    local_lons = ds['longitude'][lon_ind-buffer_lon:lon_ind+buffer_lon+1]\n",
    "    lat_ind = bisect.bisect_left(ds['latitude'], interp['latitude'])\n",
    "    local_lats = ds['latitude'][lat_ind-buffer_lat:lat_ind+buffer_lat+1]\n",
    "\n",
    "    # crop ds around desired point\n",
    "    local_ds = ds_era.sel(longitude=local_lons, latitude=local_lats)\n",
    "    ds_dims = local_ds[variables[0]].dims\n",
    "\n",
    "    # name as x,y coordinates and create grid\n",
    "    x = local_ds[ds_dims[0]].values.astype(np.float64) \n",
    "    y = local_ds[ds_dims[1]].values.astype(np.float64)\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for var in variables:\n",
    "\n",
    "        # create interpolation function and interpolate data at desired point\n",
    "        d = local_ds[var].values.astype(np.float64)\n",
    "        interpolation = RegularGridInterpolator((x, y), d, bounds_error=False, fill_value=None)\n",
    "        val = interpolation((interp[ds_dims[0]], interp[ds_dims[1]]))\n",
    "        values.append(val)\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify other plot parametres and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT PARAMETERS\n",
    "\n",
    "# set plot range and map_projection\n",
    "#==============================================================\n",
    "lat_range = [69.5, 78]\n",
    "lon_range = [197, 232]\n",
    "extent = [lon_range[0], lon_range[1], lat_range[0], lat_range[1]]\n",
    "map_projection = ccrs.NorthPolarStereo(central_longitude=205)\n",
    "#==============================================================\n",
    "\n",
    "# specify band of data to plot\n",
    "#==============================================================\n",
    "if str(sensor) == 'MODIS':\n",
    "    band = '31'   # Thermal MODIS: Infrared (TIR) at 10.780â€“11.280 micrometers\n",
    "elif str(sensor) == 'VIIRS':\n",
    "    band = 'M15'  # Thermal VIIRS: longwave IR 10.26 - 11.26 micrometers\n",
    "#==============================================================\n",
    "\n",
    "\n",
    "# set colorscale for image\n",
    "#==============================================================\n",
    "ice_cmap = mpl.cm.Blues\n",
    "# ice_cmap = cmocean.cm.ice_r\n",
    "#==============================================================\n",
    "\n",
    "\n",
    "# whether or not to suppress prints\n",
    "#==============================================================\n",
    "quiet = True\n",
    "#==============================================================\n",
    "\n",
    "# hide known warnings that result in many printed warning statements\n",
    "#==============================================================\n",
    "# ignore shapely warning for geographic plots\n",
    "import shapely\n",
    "import warnings\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
    "# pcolormesh shading warning\n",
    "warnings.filterwarnings(\"ignore\", module = \"matplotlib\\..*\" )\n",
    "warnings.filterwarnings(\"ignore\", module = \"cartopy\\..*\" )\n",
    "#==============================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_pair_data(lat, lon, _image_):\n",
    "    \n",
    "    all_lats = np.array([])\n",
    "    all_lons = np.array([])\n",
    "    all_rad = np.array([])\n",
    "\n",
    "    all_lats = np.append(all_lats, lat[0].flatten())\n",
    "    all_lons = np.append(all_lons, lon[0].flatten())\n",
    "    all_rad = np.append(all_rad, _image_[0].flatten())\n",
    "    \n",
    "    if len(lat) == 2:\n",
    "        all_lats = np.append(all_lats, lat[1].flatten())\n",
    "        all_lons = np.append(all_lons, lon[1].flatten())\n",
    "        all_rad = np.append(all_rad, _image_[1].flatten())\n",
    "        \n",
    "    return all_lats, all_lons, all_rad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.995056529498974\n",
      "39.995056524180875\n",
      "39.99505652426641\n",
      "39.995056512884304\n",
      "39.995056495866955\n",
      "39.9950564910556\n",
      "39.995056473877426\n",
      "39.99505647923447\n",
      "39.995036664730065\n",
      "39.9950334495644\n",
      "39.99498011409721\n",
      "39.99497661236586\n",
      "39.99495340994543\n",
      "39.99495260908761\n",
      "39.994935846997656\n",
      "39.99493337743982\n",
      "39.994844457205836\n",
      "39.994833322108576\n",
      "39.994791831431954\n",
      "39.994793474111056\n",
      "39.99477968590888\n",
      "39.99478424993058\n",
      "39.99482686583564\n",
      "39.99482742697302\n",
      "39.99482841259168\n",
      "39.99482782416761\n",
      "39.994776421291355\n",
      "39.99477352069719\n",
      "39.99469459015752\n",
      "39.99468863658682\n",
      "39.99464391168524\n",
      "39.99464258967147\n",
      "39.9946333326253\n",
      "39.99463317408051\n",
      "39.994640570067645\n",
      "39.99464198531139\n",
      "39.9946587835421\n",
      "39.994659566692526\n",
      "39.99466613532041\n",
      "39.99466623132732\n",
      "39.99466661874742\n",
      "39.99466642542796\n",
      "39.99465268295955\n",
      "39.99464999622242\n",
      "39.99461632134081\n",
      "39.99461544783606\n",
      "39.99460924780037\n",
      "39.994608584418714\n",
      "39.9946076428143\n",
      "39.99460864704807\n",
      "39.99462291077962\n",
      "39.9946233535481\n",
      "39.99462506772203\n",
      "39.99462511652703\n",
      "39.99462506060553\n",
      "39.99462509570618\n",
      "39.99462192609601\n",
      "39.99461992581273\n",
      "39.99461317434267\n",
      "39.994613297615246\n",
      "39.99460337301789\n",
      "39.994602572694795\n",
      "39.994605285649165\n",
      "39.994605091757705\n",
      "39.99460560312743\n",
      "39.99460565395486\n",
      "39.99460566581834\n",
      "39.99460566074902\n",
      "39.994605643115214\n",
      "39.994605616332365\n",
      "39.994604540521905\n",
      "39.99460455251733\n",
      "39.99460350296939\n",
      "39.99460335210896\n",
      "39.99460055078628\n",
      "39.994600566680795\n",
      "39.99460207695252\n",
      "39.99460211516041\n",
      "39.99460252968757\n",
      "39.99460271121728\n",
      "39.994603397901045\n",
      "39.994604016627136\n",
      "39.9946055888292\n",
      "39.99460578057357\n",
      "39.9946054578914\n",
      "39.99460549559766\n",
      "39.9945944989869\n",
      "39.99459394099691\n",
      "39.994586636447934\n",
      "39.99458675305907\n",
      "39.99458763539946\n",
      "39.99458775544312\n",
      "39.99458822801157\n",
      "39.994588221033986\n",
      "39.994563530299274\n",
      "39.99456055869549\n",
      "39.9945445259462\n",
      "39.994542506289406\n",
      "39.99453945030789\n",
      "39.9945380118314\n",
      "39.994558004340846\n",
      "39.99456098218231\n",
      "39.99460324851347\n",
      "39.99460325545578\n",
      "39.99460242096497\n",
      "39.99460224337291\n",
      "39.994589416891976\n",
      "39.99458899452396\n",
      "39.994579802577874\n",
      "39.99458011343767\n",
      "39.994584861233385\n",
      "39.994585002089345\n",
      "39.9945493297671\n",
      "39.99454378701812\n",
      "39.99445050339425\n",
      "39.994441806101456\n",
      "39.99436739618243\n",
      "39.99436002286452\n",
      "39.99431868530824\n",
      "39.99431725901857\n",
      "39.99428490755601\n",
      "39.994281113000895\n",
      "39.99425799035969\n",
      "39.99425685243447\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ">>> runtime: 4:26:45.245900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "FS = 12\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "starttime = datetime.now()\n",
    "\n",
    "# RUN TO MAKE PLOT, ADJUST APPEARANCE OF LAYERS BELOW AS NEEDED\n",
    "#==============================================================\n",
    "\n",
    "# Run through all pairs of images given in RunPair and make plots\n",
    "#----------------------------------------------------------------\n",
    "if str(RunPair) == 'All':\n",
    "    RunPair = np.arange(0,np.max(Image_Meta_paired[:,4])+1)\n",
    "for ii in RunPair:\n",
    "    # grab metadata from current_set of paired images\n",
    "    #------------------------------------------------\n",
    "    # grab current_set of paired images to run through\n",
    "    current_set = Image_Meta_paired[np.where(Image_Meta_paired[:,4]==ii)[0]]\n",
    "    # start empty lists to fill with image names, paths, and dates\n",
    "    IMG_filename=[]\n",
    "    GEO_filename=[]\n",
    "    # add data from all images in current_set to above lists\n",
    "    counter = 0\n",
    "    for image_meta in current_set:\n",
    "        # grab date and ImageName for saving from first file in current_set\n",
    "        if counter == 0:\n",
    "            ImageDate = image_meta[0]\n",
    "            ImageName = image_meta[3]+image_meta[2][0:22]\n",
    "        IMG_filename = np.append(IMG_filename, image_meta[3]+image_meta[2])\n",
    "        GEO_filename = np.append(GEO_filename, image_meta[3]+image_meta[1])\n",
    "        counter+=1\n",
    "    \n",
    "\n",
    "    if not quiet:\n",
    "        print('Save with name {}'.format(ImageName))    \n",
    "        print('Image is from: {} UTC (day {} of {})'.format(ImageDate,ImageDate.strftime('%j'), ImageDate.strftime('%Y')))\n",
    "    # grab data from current_set of paired images\n",
    "    #--------------------------------------------\n",
    "    # start empty lists to fill with imagery data and coordinates\n",
    "    _image_ = []\n",
    "    lat = []\n",
    "    lon = []\n",
    "\n",
    "    # for all images in current_set\n",
    "    for jj in range(len(current_set)):\n",
    "\n",
    "        # import imagery data, mask invalid values\n",
    "        # and import geo data\n",
    "        #-----------------------------------------\n",
    "\n",
    "        if str(sensor) == 'MODIS':\n",
    "            _level1bimage_ = load_MODISband(IMG_filename[jj], 'EV_1KM_Emissive', band, 'radiance')\n",
    "            LAT, LON = get_MODISgeo(GEO_filename[jj])\n",
    "\n",
    "        elif str(sensor) == 'VIIRS':\n",
    "            _level1bimage_ = load_VIIRS_band(IMG_filename[jj], band = 'M15')\n",
    "            LAT, LON = get_VIIRS_geo(GEO_filename[jj])\n",
    "\n",
    "\n",
    "        # add imagery and coordinates for this file to the lists\n",
    "        #-------------------------------------------------------\n",
    "        _image_.append(_level1bimage_)\n",
    "        lat.append(LAT)\n",
    "        lon.append(LON)\n",
    "\n",
    "    # determine rounded image date to 0Z, 4Z, 8Z, 12Z, 16Z, 20Z\n",
    "#     date_only = pd.to_datetime(ImageDate.date())\n",
    "#     hours = (ImageDate - date_only).total_seconds()/3600\n",
    "#     if (hours < 2):\n",
    "#         mod_date = date_only\n",
    "#     elif (hours > 2) and (hours < 5.9):\n",
    "#         mod_date = date_only + timedelta(hours=4)\n",
    "#     elif (hours > 5.9) and (hours < 10):\n",
    "#         mod_date = date_only + timedelta(hours=8)\n",
    "#     elif (hours > 10) and (hours < 14):\n",
    "#         mod_date = date_only + timedelta(hours=12)\n",
    "#     elif (hours > 14) and (hours < 18):\n",
    "#         mod_date = date_only + timedelta(hours=16)\n",
    "#     elif (hours > 18) and (hours < 22):\n",
    "#         mod_date = date_only + timedelta(hours=20)\n",
    "#     elif (hours > 22):\n",
    "#         mod_date = date_only + timedelta(hours=24)\n",
    "    \n",
    "#     mod_date = mod_date.to_pydatetime()\n",
    "#     rounded_date = ImageDate-timedelta(minutes = ImageDate.minute)\n",
    "    \n",
    "    nearest_hour_date = ImageDate.replace(second=0, microsecond=0, minute=0, hour=ImageDate.hour) + timedelta(hours=ImageDate.minute//30)\n",
    "    \n",
    "\n",
    "\n",
    "    #==============\n",
    "    # PLOT IMAGERY\n",
    "    #==============\n",
    "    # create figure\n",
    "    #--------------\n",
    "    # dynamic color scale\n",
    "    all_lats, all_lons, all_rad = flatten_pair_data(lat, lon, _image_)\n",
    "    all_rad[all_rad.data == 65533] = np.nan\n",
    "\n",
    "    cond = (all_lats > 70).astype(int)+(all_lats < 77).astype(int)+(all_lons > 200).astype(int)+(all_lons < 240).astype(int)\n",
    "    min_val = np.nanpercentile(all_rad.data[cond == 4], 1)-0.1\n",
    "    max_val = np.nanpercentile(all_rad.data[cond == 4], 99)+0.75\n",
    "    cscale = [min_val, max_val]\n",
    "    divnorm=matplotlib.colors.TwoSlopeNorm(vmin=min_val, vcenter=min_val+0.7*(max_val-min_val), vmax=max_val)\n",
    "\n",
    "    sp = 5\n",
    "    fig, ax = plt.subplots(subplot_kw=dict(projection=map_projection), figsize=(8,8), facecolor='white')\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "    ax.add_feature(cartopy.feature.OCEAN, color=ice_cmap(0.3), zorder=0)\n",
    "\n",
    "\n",
    "\n",
    "    for ii in range(0,len(_image_)):\n",
    "        ax.pcolormesh(lon[ii], lat[ii], _image_[ii],norm = divnorm,\n",
    "                      cmap=ice_cmap, shading='nearest', zorder=1, transform=ccrs.PlateCarree())\n",
    "\n",
    "    #======================\n",
    "    # ADD CARTOPY FEATURES\n",
    "    #======================\n",
    "    add_land(ax,  scale='10m', color=[0.85,0.85,0.85], alpha=1, fill_dateline_gap=True, zorder=3)\n",
    "    add_coast(ax, scale='10m', color=[0.8,0.8,0.8], linewidth=1, alpha=1, zorder=4)\n",
    "#     add_grid(ax, lats=np.arange(70,90,5), lons=np.arange(100,300,20), linewidth=1, color='gray', alpha=0.3, zorder=10)\n",
    "\n",
    "\n",
    "    # label date\n",
    "    #======================\n",
    "    add_date(fig, ax, nearest_hour_date, date_format='%Y-%m-%d %H:00',\n",
    "             boxstyle='round,pad=0.2,rounding_size=0.2',\n",
    "             method='manual', facecolor='white', edgecolor='None',\n",
    "             x = 0.0, y = 1.06, textcolor='k', fontsize=FS+4, zorder=10)\n",
    "\n",
    "    # import era5\n",
    "    #=============\n",
    "    # grab nearest date index from ECMWF file\n",
    "    if not quiet:\n",
    "        print('Add wind data: nearest date ECMWF --> {}'.format(nearest_hour_date))\n",
    "    ds_era = xr.open_dataset(ECMWF).sel(time=nearest_hour_date)\n",
    "    ds_era.close()\n",
    "    u10  = ds_era.u10.values\n",
    "    v10  = ds_era.v10.values\n",
    "    msl  = ds_era.msl.values/100\n",
    "    Lons, Lats = np.meshgrid(ds_era.longitude.values, ds_era.latitude.values)\n",
    "\n",
    "\n",
    "    # wind vectors\n",
    "    #======================\n",
    "    wind_vec = ax.quiver(Lons, Lats, *fix_cartopy_vectors(u10, v10, Lats),\n",
    "                        regrid_shape=7, scale=150, width=0.003, color=[0.6,0.6,0.6], headwidth=4, pivot='mid',\n",
    "                        headaxislength=4, headlength=5, transform=ccrs.PlateCarree(), zorder=8)\n",
    "    qk = ax.quiverkey(wind_vec, 0.44, 1.02, 10,  '10m wind\\n(10 m s$^{-1}$)',\n",
    "                      labelpos='N', coordinates='axes', fontproperties={'size':FS})\n",
    "\n",
    "    # sea level pressue\n",
    "    #======================\n",
    "#     lev = np.arange(980,1060,4)\n",
    "#     ax.contour(Lons, Lats, msl, levels = lev, linewidths = (lev-960)/40,\n",
    "#                colors=[[0.4,0.4,0.4]],\n",
    "#                zorder=10, transform=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "    # buoys\n",
    "    #======================\n",
    "    buoy_lons, buoy_lats, buoy_u, buoy_v = grab_buoy_velocities(nearest_hour_date, ds, buoy_time)\n",
    "    buoy_speed = np.sqrt(buoy_u**2+buoy_v**2)\n",
    "    ice_vec = ax.quiver(buoy_lons, buoy_lats, *fix_cartopy_vectors(buoy_u, buoy_v, buoy_lats),\n",
    "                        scale=300, width=0.0025, headwidth=5, headaxislength=5, headlength=5, transform=ccrs.PlateCarree(), zorder=8)\n",
    "    qk = ax.quiverkey(ice_vec, 0.62, 1.02, 20,  'SIDEx buoy\\n(20 cm s$^{-1}$)',\n",
    "                      labelpos='N', coordinates='axes', fontproperties={'size':FS})\n",
    "\n",
    "\n",
    "    # grab local wind speeds to buoys\n",
    "    ds_era = xr.open_dataset(ECMWF).sel(time=nearest_hour_date)\n",
    "    local_ws = np.array([])\n",
    "    for ii in range(len(buoy_lons)):\n",
    "        if np.isnan(buoy_lons[ii]):\n",
    "            local_ws = np.append(local_ws, np.nan)\n",
    "        else:\n",
    "            out = interpolate_uv(ds = ds_era,\n",
    "                                 interp_lon = buoy_lons[ii], \n",
    "                                 interp_lat = buoy_lats[ii], \n",
    "                                 variables = ['u10', 'v10'], \n",
    "                                 buffer_lon = 1, buffer_lat = 1)\n",
    "            local_u, local_v = out\n",
    "            local_ws = np.append(local_ws, np.sqrt(local_u**2+local_v**2))\n",
    "\n",
    "    buoy_cmap = cmocean.cm.haline_r\n",
    "    ax.scatter(buoy_lons, buoy_lats, s=7,\n",
    "               c=buoy_speed/local_ws, cmap=buoy_cmap, vmin=0, vmax=3,\n",
    "               edgecolor='k', lw=0.5, transform=ccrs.PlateCarree(), zorder=9)\n",
    "\n",
    "    map_extent = ax.get_extent()\n",
    "    \n",
    "    # plot buoy 23 loc    \n",
    "    time_buoy = buoy_time[bisect.bisect_left(buoy_time, nearest_hour_date)]\n",
    "    ds_crop = ds.sel(time = slice(buoy_time[0], time_buoy), buoyID = '23')\n",
    "    lat_track = ds_crop.latitude.values\n",
    "    lon_track = ds_crop.longitude.values\n",
    "    ax.plot(lon_track, lat_track, c='k', linestyle=(0,(1,1)), linewidth = 0.75, zorder = 7, transform=ccrs.PlateCarree())\n",
    "    \n",
    "\n",
    "    # inset map 1\n",
    "    #======================\n",
    "    #======================\n",
    "    #======================\n",
    "    \n",
    "    # create inset plots\n",
    "    #-------------------\n",
    "    size = 0.4\n",
    "    axins = inset_axes(ax, width=\"100%\", height=\"100%\", loc='upper left',\n",
    "                       bbox_to_anchor=(-0.455,0.025,size,size), bbox_transform=ax.transAxes, \n",
    "                       axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                       axes_kwargs=dict(map_projection=map_projection))\n",
    "    # buoys\n",
    "    #======================\n",
    "    local_buoys = ['23', '25', '26', '27', '29', '32', '33', '35', '36', '38', \n",
    "           '40', '41', '43','46', '48', '49', '50', '51']\n",
    "    ds_local = ds.sel(buoyID = local_buoys)\n",
    "    buoy_lons, buoy_lats, buoy_u, buoy_v = grab_buoy_velocities(nearest_hour_date, ds_local, buoy_time)\n",
    "    buoy_speed = np.sqrt(buoy_u**2+buoy_v**2)\n",
    "#     center_lat = buoy_lats[0]-0.0225\n",
    "#     center_lon = buoy_lons[0]-0.15\n",
    "    if np.isnan(buoy_lats[local_buoys.index('50')]):\n",
    "        center_lat = buoy_lats[local_buoys.index('23')]-0.0225\n",
    "        center_lon = buoy_lons[local_buoys.index('23')]-0.15\n",
    "    else:\n",
    "        center_lat = buoy_lats[local_buoys.index('50')]-0.0225+0.03310111728320919\n",
    "        center_lon = buoy_lons[local_buoys.index('50')]-0.15+0.0378840300131742\n",
    "    \n",
    "    # find lon, lat 40 km in either direction\n",
    "    endlon, endlat, backaz = g.fwd(center_lon, center_lat, 90, 40000)\n",
    "    buffer_lon = np.abs(center_lon-endlon)\n",
    "    endlon, endlat, backaz = g.fwd(center_lon, center_lat, 0, 40000)\n",
    "    buffer_lat = np.abs(center_lat-endlat)\n",
    "    \n",
    "#     buffer_lon = 1.1125\n",
    "#     buffer_lat = buffer_lon*np.cos(center_lat*np.pi/180)\n",
    "    extent_mini = [center_lon-buffer_lon, center_lon+buffer_lon,\n",
    "                   center_lat-buffer_lat, center_lat+buffer_lat]\n",
    "    axins.set_extent(extent_mini, ccrs.PlateCarree())\n",
    "\n",
    "    theta = np.linspace(0, 2*np.pi, 100)\n",
    "    center, radius = [0.5, 0.5], 0.5\n",
    "    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "    circle = mpath.Path(verts * radius + center)\n",
    "    axins.set_boundary(circle, transform=axins.transAxes)\n",
    "    out = verts * radius + center\n",
    "    axins.plot(out[:,0], out[:,1], c='k', lw=2, transform=axins.transAxes, zorder=10)\n",
    "#     add_land(axins,  scale='50m', color=[0.85,0.85,0.85], alpha=1, fill_dateline_gap=True, zorder=3)\n",
    "    \n",
    "    # buoys\n",
    "    #======================\n",
    "    \n",
    "    # grab local wind speeds to buoys\n",
    "    ds_era = xr.open_dataset(ECMWF).sel(time=nearest_hour_date)\n",
    "    local_ws = np.array([])\n",
    "    for ii in range(len(buoy_lons)):\n",
    "        \n",
    "        if np.isnan(buoy_lons[ii]):\n",
    "            local_ws = np.append(local_ws, np.nan)\n",
    "        else:\n",
    "            out_buoy = interpolate_uv(ds = ds_era,\n",
    "                                 interp_lon = buoy_lons[ii], \n",
    "                                 interp_lat = buoy_lats[ii], \n",
    "                                 variables = ['u10', 'v10'], \n",
    "                                 buffer_lon = 1, buffer_lat = 1)\n",
    "            local_u, local_v = out_buoy\n",
    "            local_ws = np.append(local_ws, np.sqrt(local_u**2+local_v**2))\n",
    "        \n",
    "    axins.quiver(buoy_lons, buoy_lats, *fix_cartopy_vectors(buoy_u, buoy_v, buoy_lats),\n",
    "              scale=110, width=0.008, headwidth=5, headaxislength=5, headlength=5, transform=ccrs.PlateCarree(), zorder=8)\n",
    "    buoyc = axins.scatter(buoy_lons, buoy_lats, s=15,\n",
    "                          c=buoy_speed/local_ws, cmap=buoy_cmap, vmin=0, vmax=3,\n",
    "                          edgecolor='k', lw=0.75, transform=ccrs.PlateCarree(), zorder=9)\n",
    "    add_colorbar(fig, axins, [buoyc], cb_placement='top', cb_orientation='auto', \n",
    "                 cb_width=0.015, cb_length_fraction=[0.775, 0.965], cb_pad=0.015, cb_ticks=[0,1.5,3], \n",
    "                 cb_ticklabels=['0%','1.5%','3%'], cb_extend='neither', cb_label='Buoy/wind speed ratio', labelpad='auto',\n",
    "                 cb_label_placement='auto', cb_tick_placement='auto', cb_labelsize=FS, \n",
    "                 draw_edges=False, edge_params=['k', 2])\n",
    "    \n",
    "    # imagery\n",
    "    #========\n",
    "    cond = (all_lats > center_lat-buffer_lat).astype(int)+(all_lats < center_lat+buffer_lat).astype(int)+(all_lons > center_lon-buffer_lon+360).astype(int)+(all_lons < center_lon+buffer_lon+360).astype(int)\n",
    "    min_val = np.nanpercentile(all_rad.data[cond == 4], 1)-0.1\n",
    "    max_val = np.nanpercentile(all_rad.data[cond == 4], 99)+0.75\n",
    "    cscale = [min_val, max_val]\n",
    "    divnorm=matplotlib.colors.TwoSlopeNorm(vmin=min_val, vcenter=min_val+0.7*(max_val-min_val), vmax=max_val)\n",
    "    for ii in range(0,len(_image_)):\n",
    "        axins.pcolormesh(lon[ii], lat[ii], _image_[ii],\n",
    "                         norm = divnorm,\n",
    "#                          vmin=cscale[0], vmax=cscale[1],\n",
    "                         cmap=ice_cmap, shading='nearest', zorder=1, transform=ccrs.PlateCarree(), \n",
    "                         clip_path=(circle, axins.transAxes))\n",
    "\n",
    "    \n",
    "    ax.text(-0.25, 0.425, '40 km radius', horizontalalignment='center', size=FS, clip_on=False, transform=ax.transAxes, zorder=10)\n",
    "    \n",
    "    \n",
    "    # inset map 2\n",
    "    #======================\n",
    "    #======================\n",
    "    #======================\n",
    "    \n",
    "    # create inset plots\n",
    "    #-------------------\n",
    "    size = 0.5\n",
    "    axins2 = inset_axes(ax, width=\"100%\", height=\"100%\", loc='upper left',\n",
    "                       bbox_to_anchor=(-0.5,0.5125,size,size), bbox_transform=ax.transAxes, \n",
    "                       axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                       axes_kwargs=dict(map_projection=map_projection))\n",
    "    # set extent\n",
    "    axins2.set_extent([0, 359, 65, 90], ccrs.PlateCarree())\n",
    "    # Compute a circle in axes coordinates, use as a boundary for the map. \n",
    "    # Pan/zoom - the boundary will be permanently circular.\n",
    "    theta = np.linspace(0, 2*np.pi, 100)\n",
    "    center, radius = [0.5, 0.5], 0.5\n",
    "    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "    circle = mpath.Path(verts * radius + center)\n",
    "    axins2.set_boundary(circle, transform=axins2.transAxes)\n",
    "\n",
    "    mesh = axins2.contourf(Lons, Lats, msl, cmap=cmocean.cm.matter, vmin=980, vmax = 1040, \n",
    "                       extend='both', levels=np.arange(980,1044,4), zorder=1, transform=ccrs.PlateCarree())\n",
    "\n",
    "    add_land(axins2,  scale='50m', color=[0.85,0.85,0.85], alpha=1, fill_dateline_gap=True, zorder=3)\n",
    "    add_grid(axins2, lats=np.arange(60,90,30), lons=np.arange(0,360,45), \n",
    "             linewidth=0.5, color='gray', alpha=1, zorder=4)\n",
    "\n",
    "    add_colorbar(fig, axins2, [mesh], cb_placement='top', cb_orientation='auto', \n",
    "                 cb_width=0.015, cb_length_fraction=[-0.375, -0.1], cb_pad=0.01, \n",
    "                 cb_ticks=[980,1010,1040], cb_ticklabels='auto', cb_label='Sea level pressure (hPa)', \n",
    "#                  cb_ticks=[980,1040], cb_ticklabels=['980 hPa', '1040 hPa'], cb_label='ERA5 sea level pressure', \n",
    "                 cb_extend='neither', labelpad='auto',\n",
    "                 cb_label_placement='auto', cb_tick_placement='auto', cb_labelsize=FS, \n",
    "                 draw_edges=False, edge_params=['k', 2])\n",
    "    axins2.plot([map_extent[0],map_extent[0],map_extent[1],map_extent[1],map_extent[0]], \n",
    "                [map_extent[2],map_extent[3],map_extent[3],map_extent[2],map_extent[2]], \n",
    "                c='k', lw=2, alpha=1, zorder=5)\n",
    "   \n",
    "    # compute forward and back azimuths, plus distance\n",
    "    az12,az21,distance = g.inv(center_lon, center_lat, center_lon+buffer_lon, center_lat)\n",
    "    print(distance/1000)\n",
    "    circle_lon = np.array([])\n",
    "    circle_lat = np.array([])\n",
    "    for az in np.linspace(-180,180,20):\n",
    "        endlon, endlat, backaz = g.fwd(center_lon, center_lat, az, distance)\n",
    "        circle_lon = np.append(circle_lon, endlon)\n",
    "        circle_lat = np.append(circle_lat, endlat)\n",
    "    axins2.plot(circle_lon, circle_lat, c='k', lw=1,  transform=ccrs.PlateCarree(), zorder=100)\n",
    "\n",
    "\n",
    "    \n",
    "#     remove automatic image border\n",
    "#     ax.spines['geo'].set_linewidth(0)\n",
    "\n",
    "#     ax.text(0.05, 0.03, 'Thermal infrared VIIRS, MODIS imagery', c=[0.7,0.7,0.7], horizontalalignment='left', verticalalignment='center', size=FS-1.5, clip_on=False, transform=ax.transAxes, zorder=10)\n",
    "    ax.text(0.975, -0.015, 'Animation by MacKenzie Jewell', c=[0.7,0.7,0.7], horizontalalignment='right', verticalalignment='top', size=FS-2.5, clip_on=False, transform=ax.transAxes, zorder=10)\n",
    "    \n",
    "    fig.savefig(ImageName+'_v1.png',bbox_inches=\"tight\", pad_inches = 0.3, dpi=300)\n",
    "    fig.clear()\n",
    "    plt.close(fig) \n",
    "\n",
    "    \n",
    "\n",
    "print('\\n\\n\\n')\n",
    "print(f'>>> runtime: {datetime.now()-starttime}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenvOSU",
   "language": "python",
   "name": "geoenvosu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
