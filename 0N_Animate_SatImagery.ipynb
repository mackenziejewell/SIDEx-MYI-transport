{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0N_Animate_SatImagery\n",
    "\n",
    "---\n",
    "Read in and plot thermal infrared image(s) from MODIS and VIIRS level1b radiances. \n",
    "\n",
    "Overlay ERA5 atmospheric reanalysis surface atmospheric conditions (doi: 10.24381/cds.adbb2d47) and SIDEx buoy positions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (LIB_download_NASALAADS.py, line 39)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/opt/anaconda3/envs/geoenvOSU/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3460\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\n\u001b[0;31m    from LIB_download_NASALAADS import download_laads\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/GitHub/SIDEx-MYI-transport/./scripts/LIB_download_NASALAADS.py:39\u001b[0;36m\u001b[0m\n\u001b[0;31m    if not quiet:\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from common_imports import *\n",
    "\n",
    "\n",
    "# homemade functions\n",
    "sys.path.append('./scripts/')\n",
    "from LIB_download_NASALAADS import download_laads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import dependencies\n",
    "# import glob\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "\n",
    "# import xarray as xr\n",
    "\n",
    "\n",
    "# from pyhdf.SD import SD, SDC\n",
    "# import netCDF4\n",
    "# import numpy as np\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# from matplotlib import pyplot as plt\n",
    "# import matplotlib.colors\n",
    "\n",
    "# import cartopy\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cfeat\n",
    "\n",
    "\n",
    "# import datetime\n",
    "\n",
    "# from shapely.geometry import Point\n",
    "# from shapely.geometry.polygon import Polygon\n",
    "\n",
    "\n",
    "\n",
    "# # import my own functions from within the same repository \n",
    "# #********************************************************\n",
    "# sys.path.append('./scripts/')\n",
    "\n",
    "# # functions from my own set of notebooks in plotMODIS\n",
    "# from LIB_plot_MODIS import (get_MODISgeo, load_MODISband, colorscale_range, \n",
    "#                             get_MODISdate, crop_makepoly_geo)\n",
    "\n",
    "# from LIB_geo_plot import (fix_cartopy_vectors, add_land, add_coast, add_grid,\n",
    "#                           add_date, add_mslp, add_vectors)\n",
    "\n",
    "# from LIB_print_func import print_line, print_boxed\n",
    "\n",
    "# from get_camp_track import GetCampPosition_cln\n",
    "\n",
    "\n",
    "# from LIB_plot_VIIRS import load_VIIRS_band, get_VIIRS_geo\n",
    "\n",
    "\n",
    "# from LIB_plot_sat import pair_images_meta, plot_singleband_sat\n",
    "\n",
    "\n",
    "\n",
    "# # from analyze_SIDExbuoy import open_buoy_data, calc_velocity\n",
    "\n",
    "\n",
    "# # from ipynb.fs.full.LIB_MODIS_func import get_MODISgeo, load_MODISband, colorscale_range, get_MODISdate, crop_makepoly_geo, pair_images_meta\n",
    "# # from ipynb.fs.full.LIB_ECMWF_func import get_ECMWFdate, get_ecmwf_data, crop_ecmwf_byextent\n",
    "# # from ipynb.fs.full.LIB_geo_plotting import (base_plot, add_feat, add_date, add_winds, \n",
    "# #                                             fix_cartopy_vectors, add_mslp, GetCampPosition_cln,GetCampTrack_cln)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_laads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdownload_laads\u001b[49m(file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOD03.A2021060.0645.061.2021060125526.hdf\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      2\u001b[0m                target_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/mackenziejewell/Desktop/temp/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                token_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/mackenziejewell/Desktop/LAADS_token.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, quiet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'download_laads' is not defined"
     ]
    }
   ],
   "source": [
    "download_laads(file = 'MOD03.A2021060.0645.061.2021060125526.hdf', \n",
    "               target_dir = '/Users/mackenziejewell/Desktop/temp/',\n",
    "               token_txt = '/Users/mackenziejewell/Desktop/LAADS_token.txt', quiet = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target directory to save imagery\n",
    "#===================================================\n",
    "target_dir = '/Users/mackenziejewell/Desktop/temp/' \n",
    "#===================================================\n",
    "\n",
    "# path to text file containing LAADS DAAC Bearer token\n",
    "#===================================================\n",
    "token_txt = '/Users/mackenziejewell/Desktop/LAADS_token.txt'\n",
    "#===================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================\n",
    "file = 'MOD03.A2021060.0645.061.2021060125526.hdf'\n",
    "file = 'VJ103MOD.A2021060.1348.021.2021072211652.nc'\n",
    "# file = 'VNP03MOD.A2021061.1412.002.2021127001850.nc'\n",
    "#==================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/5201/VJ103MOD/2021/060/VJ103MOD.A2021060.1348.021.2021072211652.nc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "group = file.split('.')[0]\n",
    "collection = file.split('.')[3]\n",
    "\n",
    "# for some reason VIIRS collection numbers are different than those in their file names\n",
    "if collection == '021':\n",
    "    collection = '5201'\n",
    "elif collection == '002':\n",
    "    collection = '5200'\n",
    "    \n",
    "date_string = file.split('.A')[1].split('.')[0]\n",
    "year = date_string[:4]\n",
    "jday = date_string[4:]\n",
    "jday\n",
    "\n",
    "# generate LAADS DAAC url to download file\n",
    "ladsweb_url = f'https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/{collection}/{group}/{year}/{jday}/{file}'\n",
    "ladsweb_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/mackenziejewell/Desktop/temp/VJ103MOD.A2021060.1348.021.2021072211652.nc',\n",
       " <http.client.HTTPMessage at 0x7fe318cb8bb0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# request download\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('Authorization', f'Bearer {LAADStoken}')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# download to target_dir\n",
    "urllib.request.urlretrieve(ladsweb_url, target_dir+file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MOD03.A2021060.0645.061.2021060125526.hdf'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urllib.request.urlretrieve(ladsweb_url,target_dir)\n",
    "Creative Commons License\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import level1b MODIS files (HDF and GEO)\n",
    "Download from: https://ladsweb.modaps.eosdis.nasa.gov/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search in single folder: /Volumes/Jewell_EasyStore/SIDEx2021/Event_Apr15/VIIRS_check/check/\n",
      "Pair 0\n",
      "------\n",
      "2021-04-14 10:48:00\n",
      "\n",
      "Pair 1\n",
      "------\n",
      "2021-04-14 11:36:00\n",
      "\n",
      "Pair 2\n",
      "------\n",
      "2021-04-14 12:24:00\n",
      "2021-04-14 12:30:00\n",
      "\n",
      "Pair 3\n",
      "------\n",
      "2021-04-14 13:18:00\n",
      "\n",
      "Pair 4\n",
      "------\n",
      "2021-04-14 14:06:00\n",
      "2021-04-14 14:12:00\n",
      "\n",
      "Pair 5\n",
      "------\n",
      "2021-04-14 14:54:00\n",
      "2021-04-14 15:00:00\n",
      "\n",
      "Pair 6\n",
      "------\n",
      "2021-04-14 15:48:00\n",
      "\n",
      "Pair 7\n",
      "------\n",
      "2021-04-14 16:36:00\n",
      "2021-04-14 16:42:00\n",
      "\n",
      "Pair 8\n",
      "------\n",
      "2021-04-14 17:24:00\n",
      "2021-04-14 17:30:00\n",
      "\n",
      "Pair 9\n",
      "------\n",
      "2021-04-14 18:18:00\n",
      "\n",
      "Pair 10\n",
      "------\n",
      "2021-04-14 19:06:00\n",
      "\n",
      "Pair 11\n",
      "------\n",
      "2021-04-14 19:54:00\n",
      "2021-04-14 20:00:00\n",
      "\n",
      "Pair 12\n",
      "------\n",
      "2021-04-14 20:42:00\n",
      "2021-04-14 20:48:00\n",
      "\n",
      "Pair 13\n",
      "------\n",
      "2021-04-14 21:36:00\n",
      "2021-04-14 21:42:00\n",
      "\n",
      "Pair 14\n",
      "------\n",
      "2021-04-14 22:24:00\n",
      "2021-04-14 22:30:00\n",
      "\n",
      "Pair 15\n",
      "------\n",
      "2021-04-14 23:18:00\n",
      "\n",
      "Pair 16\n",
      "------\n",
      "2021-04-15 11:18:00\n",
      "\n",
      "Pair 17\n",
      "------\n",
      "2021-04-15 12:06:00\n",
      "2021-04-15 12:12:00\n",
      "\n",
      "Pair 18\n",
      "------\n",
      "2021-04-15 13:00:00\n",
      "\n",
      "Pair 19\n",
      "------\n",
      "2021-04-15 13:48:00\n",
      "\n",
      "Pair 20\n",
      "------\n",
      "2021-04-15 14:36:00\n",
      "2021-04-15 14:42:00\n",
      "\n",
      "Pair 21\n",
      "------\n",
      "2021-04-15 15:24:00\n",
      "2021-04-15 15:30:00\n",
      "\n",
      "Pair 22\n",
      "------\n",
      "2021-04-15 16:18:00\n",
      "\n",
      "Pair 23\n",
      "------\n",
      "2021-04-15 17:06:00\n",
      "2021-04-15 17:12:00\n",
      "\n",
      "Pair 24\n",
      "------\n",
      "2021-04-15 18:00:00\n",
      "\n",
      "Pair 25\n",
      "------\n",
      "2021-04-15 18:48:00\n",
      "\n",
      "Pair 26\n",
      "------\n",
      "2021-04-15 19:36:00\n",
      "2021-04-15 19:42:00\n",
      "\n",
      "Pair 27\n",
      "------\n",
      "2021-04-15 20:24:00\n",
      "2021-04-15 20:30:00\n",
      "\n",
      "Pair 28\n",
      "------\n",
      "2021-04-15 21:18:00\n",
      "\n",
      "Pair 29\n",
      "------\n",
      "2021-04-15 22:06:00\n",
      "2021-04-15 22:12:00\n",
      "\n",
      "Pair 30\n",
      "------\n",
      "2021-04-15 23:00:00\n",
      "\n",
      "Pair 31\n",
      "------\n",
      "2021-04-15 23:48:00\n",
      "\n",
      "Pair 32\n",
      "------\n",
      "2021-04-16 11:00:00\n",
      "\n",
      "Pair 33\n",
      "------\n",
      "2021-04-16 11:48:00\n",
      "\n",
      "Pair 34\n",
      "------\n",
      "2021-04-16 12:36:00\n",
      "2021-04-16 12:42:00\n",
      "\n",
      "Pair 35\n",
      "------\n",
      "2021-04-16 13:30:00\n",
      "\n",
      "Pair 36\n",
      "------\n",
      "2021-04-16 14:18:00\n",
      "2021-04-16 14:24:00\n",
      "\n",
      "Pair 37\n",
      "------\n",
      "2021-04-16 15:06:00\n",
      "2021-04-16 15:12:00\n",
      "\n",
      "Pair 38\n",
      "------\n",
      "2021-04-16 16:00:00\n",
      "\n",
      "Pair 39\n",
      "------\n",
      "2021-04-16 16:48:00\n",
      "\n",
      "Pair 40\n",
      "------\n",
      "2021-04-16 17:42:00\n",
      "\n",
      "Pair 41\n",
      "------\n",
      "2021-04-16 18:30:00\n",
      "\n",
      "Pair 42\n",
      "------\n",
      "2021-04-16 19:18:00\n",
      "2021-04-16 19:24:00\n",
      "\n",
      "Pair 43\n",
      "------\n",
      "2021-04-16 20:06:00\n",
      "2021-04-16 20:12:00\n",
      "\n",
      "Pair 44\n",
      "------\n",
      "2021-04-16 21:00:00\n",
      "\n",
      "Pair 45\n",
      "------\n",
      "2021-04-16 21:48:00\n",
      "\n",
      "Pair 46\n",
      "------\n",
      "2021-04-16 22:42:00\n",
      "\n",
      "Pair 47\n",
      "------\n",
      "2021-04-16 23:30:00\n",
      "\n",
      "Pair 48\n",
      "------\n",
      "2021-04-17 11:30:00\n",
      "\n",
      "Pair 49\n",
      "------\n",
      "2021-04-17 12:18:00\n",
      "2021-04-17 12:24:00\n",
      "\n",
      "Pair 50\n",
      "------\n",
      "2021-04-17 13:12:00\n",
      "\n",
      "Pair 51\n",
      "------\n",
      "2021-04-17 14:00:00\n",
      "2021-04-17 14:06:00\n",
      "\n",
      "Pair 52\n",
      "------\n",
      "2021-04-17 14:48:00\n",
      "2021-04-17 14:54:00\n",
      "\n",
      "Pair 53\n",
      "------\n",
      "2021-04-17 15:42:00\n",
      "\n",
      "Pair 54\n",
      "------\n",
      "2021-04-17 16:30:00\n",
      "\n",
      "Pair 55\n",
      "------\n",
      "2021-04-17 17:18:00\n",
      "2021-04-17 17:24:00\n",
      "\n",
      "Pair 56\n",
      "------\n",
      "2021-04-17 18:12:00\n",
      "\n",
      "Pair 57\n",
      "------\n",
      "2021-04-17 19:00:00\n",
      "2021-04-17 19:06:00\n",
      "\n",
      "Pair 58\n",
      "------\n",
      "2021-04-17 19:48:00\n",
      "2021-04-17 19:54:00\n",
      "\n",
      "Pair 59\n",
      "------\n",
      "2021-04-17 20:42:00\n",
      "\n",
      "Pair 60\n",
      "------\n",
      "2021-04-17 21:30:00\n",
      "\n",
      "Pair 61\n",
      "------\n",
      "2021-04-17 22:18:00\n",
      "2021-04-17 22:24:00\n",
      "\n",
      "Pair 62\n",
      "------\n",
      "2021-04-17 23:12:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set paths for location of level1b hdf and geolocation files\n",
    "# set provided folder type as path to folder and other as []\n",
    "MainFolder = [] \n",
    "SingleFolder = []\n",
    "#==============================================================\n",
    "# MainFolder = '/Volumes/Jewell_EasyStore/SIDEx2021/img_buoy_3daily/VIIRSNP_download/'\n",
    "SingleFolder = '/Volumes/Jewell_EasyStore/SIDEx2021/Event_Apr15/VIIRS_check/check/'\n",
    "#==============================================================\n",
    "\n",
    "\n",
    "#==============================================================\n",
    "sensor = 'VIIRS'\n",
    "# sensor = 'MODIS'\n",
    "#==============================================================\n",
    "\n",
    "if str(sensor) == 'VIIRS':\n",
    "    satellite_labels = [('VNP03MOD','VNP02MOD'), ('VJ103MOD','VJ102MOD')]\n",
    "elif str(sensor) == 'MODIS':\n",
    "    satellite_labels = [('MOD03','MOD021KM'), ('MYD03','MYD021KM')]\n",
    "    \n",
    "\n",
    "Image_Meta_paired = pair_images_meta(MainFolder = MainFolder, SingleFolder = SingleFolder, \n",
    "                                     sensor = sensor, satellite_labels = satellite_labels,\n",
    "                                     min_geofile_sizeMB = 28, min_imfile_sizeMB = 50, max_diff_minutes = 20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find existing png files to save time running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_png = []\n",
    "# for file in os.listdir(SingleFolder):\n",
    "#     if file[-7:] == '_v3.png':\n",
    "#         existing_png.append(file)\n",
    "        \n",
    "# existing_png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify which pairs of images to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which pairs of images to plot\n",
    "# either 'All' or index(es) of images to plot (e.g. [1,3,6])\n",
    "#==============================================================\n",
    "# RunPair = [3] \n",
    "# RunPair = np.arange(29, 31+1) \n",
    "RunPair = 'All'\n",
    "#=============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECMWF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name and directory for ECMWF atmospheric data (nc file type)\n",
    "# or set = None if you don't want to include\n",
    "#==============================================================\n",
    "# ECMWF_winds = None\n",
    "ECMWF_mslp = None\n",
    "\n",
    "ECMWF_winds = '/Volumes/Jewell_EasyStore/ECMWF/annual/hourly/ERA5_2021.nc'\n",
    "# ECMWF_mslp = '/Volumes/Jewell_EasyStore/ECMWF/annual/hourly/ERA5_2021.nc'\n",
    "#==============================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buoy coordinate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files:\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-23_300534061090050_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-24_300534061090090_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-25_300534061091050_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-26_300534061091060_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-27_300534061091070_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-28_300534061093020_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-29_300534061093030_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-31_300534061093070_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-32_300534061094090_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-33_300534061095060_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-34-1_300534061095090_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-34-2_300534061095090_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-35_300534061096000_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-36_300534061096010_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-37_300534061096020_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-38_300534061096060_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-39_300534061097010_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-40_300534061097050_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-41_300534061098010_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-42_300534061098040_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-43_300534061098050_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-44_300534061099010_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-45_300534061980500_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-46_300534061982520_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-47_300534061984510_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-48_300534061984530_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-49_300534061984570_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-50_300534061985550_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-51_300534061986590_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-52_300534061987530_interp.csv\n",
      "/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-53_300534061988500_interp.csv\n"
     ]
    }
   ],
   "source": [
    "# set list of path+name of csv files containing coordinates\n",
    "# or set = None if not adding buoy coordinates\n",
    "#==============================================================\n",
    "# csv_directory = None\n",
    "csv_directory = '/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/'\n",
    "#==============================================================\n",
    "\n",
    "buoys_to_exclude = ['OSU-IT-30_300534061093040_interp.csv']\n",
    "\n",
    "\n",
    "csv_files = []\n",
    "if csv_directory != None:\n",
    "    files = sorted(list(glob.glob1(csv_directory, \"*.csv\")));\n",
    "    print('CSV files:')\n",
    "    for ii in range(len(files)):\n",
    "        if 'sidex_deployments_v1' not in files[ii] and files[ii] not in buoys_to_exclude:\n",
    "            csv_files.append(csv_directory+files[ii])\n",
    "            print(csv_directory+files[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OSU-IT-53_300534061988500_interp.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify other plot parametres and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT PARAMETERS\n",
    "# specify whether or not to add date and cartopy map features\n",
    "# set True or False to include or exclude these data layers\n",
    "#==============================================================\n",
    "add_date_to_plot = True\n",
    "add_cartopy_to_plot = True\n",
    "#==============================================================\n",
    "\n",
    "# set plot range and map_projection\n",
    "#==============================================================\n",
    "# narrow around SIDEX camp\n",
    "# lon_range = [200, 220]   # specify lon range to plot\n",
    "# lat_range = [70,74]   # specify lat range to plot\n",
    "\n",
    "# lon_range = [195, 225]   # specify lon range to plot\n",
    "# lat_range = [70,76]   # specify lat range to plot\n",
    "\n",
    "# v3\n",
    "# lon_range = [196.5, 226.5]   # specify lon range to plot\n",
    "# lat_range = [69.5,76]   # specify lat range to plot\n",
    "\n",
    "# april 15 event\n",
    "lon_range = [202.5,213.75]   # specify lon range to plot\n",
    "lat_range = [70.35,72.9]   # specify lat range to plot\n",
    "\n",
    "\n",
    "extent = [lon_range[0], lon_range[1], lat_range[0], lat_range[1]]\n",
    "map_projection = ccrs.NorthPolarStereo(central_longitude=205)\n",
    "#==============================================================\n",
    "\n",
    "# specify band of data to plot\n",
    "#==============================================================\n",
    "if str(sensor) == 'MODIS':\n",
    "    band = '31'   # Thermal MODIS: Infrared (TIR) at 10.780â€“11.280 micrometers\n",
    "elif str(sensor) == 'VIIRS':\n",
    "    band = 'M15'  # Thermal VIIRS: longwave IR 10.26 - 11.26 micrometers\n",
    "#==============================================================\n",
    "\n",
    "\n",
    "# set colorscale for image\n",
    "#==============================================================\n",
    "# cscale = [2.5, 3.6, 4.25, 6.25] #  [2, 3.6, 4.25, 6.25] # [2, 3.5, 4.5, 6.25] # OR USE: colorscale_range(_image_) to find min/max from current list of image radiances\n",
    "# cscale = [2.5, 3.55, 4.25, 6.25]\n",
    "# cscale = [2.75, 5.25]\n",
    "\n",
    "# cscale = [2.5, 6]\n",
    "# cscale = [3, 6.5]\n",
    "#==============================================================\n",
    "\n",
    "\n",
    "# whether or not to suppress prints\n",
    "#==============================================================\n",
    "quiet = True\n",
    "#==============================================================\n",
    "\n",
    "# hide known warnings that result in many printed warning statements\n",
    "#==============================================================\n",
    "# ignore shapely warning for geographic plots\n",
    "import shapely\n",
    "import warnings\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
    "# pcolormesh shading warning\n",
    "warnings.filterwarnings(\"ignore\", module = \"matplotlib\\..*\" )\n",
    "warnings.filterwarnings(\"ignore\", module = \"cartopy\\..*\" )\n",
    "#==============================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Jewell_EasyStore/SIDEx2021/Event_Apr15/VIIRS_check/check/VJ102MOD.A2021106.1236\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ">>> runtime: 0:01:05.610983\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# RUN TO MAKE PLOT, ADJUST APPEARANCE OF LAYERS BELOW AS NEEDED\n",
    "#==============================================================\n",
    "\n",
    "# Run through all pairs of images given in RunPair and make plots\n",
    "#----------------------------------------------------------------\n",
    "if str(RunPair) == 'All':\n",
    "    RunPair = np.arange(0,np.max(Image_Meta_paired[:,4])+1)\n",
    "for ii in RunPair:\n",
    "    # grab metadata from current_set of paired images\n",
    "    #------------------------------------------------\n",
    "    # grab current_set of paired images to run through\n",
    "    current_set = Image_Meta_paired[np.where(Image_Meta_paired[:,4]==ii)[0]]\n",
    "    # start empty lists to fill with image names, paths, and dates\n",
    "    IMG_filename=[]\n",
    "    GEO_filename=[]\n",
    "    # add data from all images in current_set to above lists\n",
    "    counter = 0\n",
    "    for image_meta in current_set:\n",
    "        # grab date and ImageName for saving from first file in current_set\n",
    "        if counter == 0:\n",
    "            ImageDate = image_meta[0]\n",
    "            ImageName = image_meta[3]+image_meta[2][0:22]\n",
    "        IMG_filename = np.append(IMG_filename, image_meta[3]+image_meta[2])\n",
    "        GEO_filename = np.append(GEO_filename, image_meta[3]+image_meta[1])\n",
    "        counter+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # only run if image was not already created!!\n",
    "    #=================\n",
    "    #=================\n",
    "    #=================\n",
    "    if ImageName.split('/')[-1]+'_v3.png' not in existing_png:\n",
    "        \n",
    "        if not quiet:\n",
    "            print('Save with name {}'.format(ImageName))    \n",
    "            print('Image is from: {} UTC (day {} of {})'.format(ImageDate,ImageDate.strftime('%j'), ImageDate.strftime('%Y')))\n",
    "        # grab data from current_set of paired images\n",
    "        #--------------------------------------------\n",
    "        # start empty lists to fill with imagery data and coordinates\n",
    "        _image_ = []\n",
    "        lat = []\n",
    "        lon = []\n",
    "\n",
    "        # for all images in current_set\n",
    "        for jj in range(len(current_set)):\n",
    "\n",
    "            # import imagery data, mask invalid values\n",
    "            # and import geo data\n",
    "            #-----------------------------------------\n",
    "\n",
    "            if str(sensor) == 'MODIS':\n",
    "                _level1bimage_ = load_MODISband(IMG_filename[jj], 'EV_1KM_Emissive', band, 'radiance')\n",
    "                LAT, LON = get_MODISgeo(GEO_filename[jj])\n",
    "\n",
    "            elif str(sensor) == 'VIIRS':\n",
    "                _level1bimage_ = load_VIIRS_band(IMG_filename[jj], band = 'M15')\n",
    "                LAT, LON = get_VIIRS_geo(GEO_filename[jj])\n",
    "\n",
    "\n",
    "            # add imagery and coordinates for this file to the lists\n",
    "            #-------------------------------------------------------\n",
    "            _image_.append(_level1bimage_)\n",
    "            lat.append(LAT)\n",
    "            lon.append(LON)\n",
    "\n",
    "            \n",
    "        # create custom colorscale\n",
    "#         _min, _max = colorscale_range(_image_)\n",
    "#         CSCALE = [_min+0.5, _max-0.5]\n",
    "        \n",
    "        #==============\n",
    "        # PLOT IMAGERY\n",
    "        #==============\n",
    "        # create figure\n",
    "        #--------------\n",
    "        \n",
    "        if ImageDate <= datetime.datetime(2021, 4, 15, 18, 0):\n",
    "            cscale = [3, 6.5]\n",
    "        elif ImageDate <= datetime.datetime(2021, 4, 16, 5, 0):\n",
    "            cscale = [3.2, 6.6]\n",
    "        elif ImageDate <= datetime.datetime(2021, 4, 16, 16, 0):\n",
    "            cscale = [3, 6.5]\n",
    "        elif ImageDate <= datetime.datetime(2021, 4, 16, 18, 0):\n",
    "            cscale = [3.15, 6.65]\n",
    "        elif ImageDate <= datetime.datetime(2021, 4, 16, 22, 0):\n",
    "            cscale = [3.4, 6.8]\n",
    "        elif ImageDate <= datetime.datetime(2021, 4, 17, 10, 0):\n",
    "            cscale = [3.5, 6.8]\n",
    "        elif ImageDate <= datetime.datetime(2021, 4, 17, 18, 0):\n",
    "            cscale = [3.6, 6.8]\n",
    "        else:\n",
    "            cscale = [4.5, 6.8]\n",
    "            \n",
    "        fig, ax = plt.subplots(subplot_kw=dict(projection=map_projection), figsize=(10, 12), facecolor='white')\n",
    "        ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "        plot_singleband_sat(ax, lat, lon, _image_, cmap='Greys', \n",
    "                            \n",
    "                            cscale=cscale, \n",
    "                            \n",
    "                            shading='nearest', zorder=1)\n",
    "\n",
    "        #======================\n",
    "        # ADD CARTOPY FEATURES\n",
    "        #======================\n",
    "        if add_cartopy_to_plot == True:\n",
    "    #         add_land(ax,  scale='50m', color='gray', alpha=1, fill_dateline_gap=True, zorder=2)\n",
    "            add_coast(ax, scale='10m', color='k', linewidth=1, alpha=1, zorder=3)\n",
    "            add_grid(ax,  lats=np.arange(70,80,2), lons=np.arange(160,260,10), linewidth=1, color='gray', alpha=0.5, zorder=4)\n",
    "\n",
    "        #======================\n",
    "        # ADD DATE\n",
    "        #======================\n",
    "        if add_date_to_plot == True:\n",
    "            add_date(fig, ax, ImageDate, date_format='%b %d, %Y (%H:%M UTC)',\n",
    "                     boxstyle='round,pad=0.2,rounding_size=0.2',\n",
    "                     method='manual', facecolor='white', edgecolor='None',\n",
    "                     x = 0.55, y = -0.02, textcolor='k', fontsize=18, zorder=10)\n",
    "\n",
    "\n",
    "        #======================\n",
    "        # ADD BUOY COORDINATES\n",
    "        #======================\n",
    "        if csv_directory != None:\n",
    "\n",
    "            # plot buoy drift\n",
    "            #----------------\n",
    "            buffer_hours = 0.5\n",
    "            for buoy_file in csv_files:\n",
    "\n",
    "                # Get the camp position at the image acquisition time\n",
    "                ([lon_buoy, lat_buoy], hour_diff) = GetCampPosition_cln(buoy_file, ImageDate)            \n",
    "\n",
    "                # if date within buoy time range, plot nearest point\n",
    "                if lat_buoy != -999 and abs(hour_diff) < buffer_hours:\n",
    "                    if lon_buoy < 0:\n",
    "                        lon_buoy += 360\n",
    "\n",
    "                    # plot point (from GetCampPosition_cln)\n",
    "                    ax.scatter(lon_buoy, lat_buoy, \n",
    "                               linewidth=0.2, marker='.', facecolor='deepskyblue', edgecolor='blue',s=5,\n",
    "                               transform=ccrs.PlateCarree(), zorder=8)\n",
    "\n",
    "                    # re-open data and crop to find drift over desired time range\n",
    "                    #------------------------------------------------------------\n",
    "                    out = open_buoy_data(buoy_file, \n",
    "                                         start_date = ImageDate-datetime.timedelta(hours=0.25), \n",
    "                                         end_date = ImageDate+datetime.timedelta(hours=0.25))\n",
    "                    lon_track, lat_track, time_track, df_buoy = out\n",
    "\n",
    "\n",
    "                    if len(df_buoy) > 0:\n",
    "\n",
    "                        # grab first and last times of day\n",
    "                        lon_single = np.array([lon_track[0],lon_track[-1]])\n",
    "                        lat_single = np.array([lat_track[0],lat_track[-1]])\n",
    "                        time_single = np.array([time_track[0],time_track[-1]])\n",
    "\n",
    "                        # calculate velocity\n",
    "                        u, v, time, dx, dy, dist = calc_velocity(lon_track=lon_single, \n",
    "                                                                 lat_track=lat_single, \n",
    "                                                                 time_track=time_single, \n",
    "                                                                 step=1)\n",
    "                        \n",
    "                        # time diff between image and velocity\n",
    "                        DT = abs((time[0]-ImageDate).total_seconds())/60\n",
    "\n",
    "                        if DT > 20:\n",
    "                            COL = 'green'\n",
    "                        else:\n",
    "                            COL = 'deepskyblue'\n",
    "                        # plot drift vector from open_buoy_data / calc_velocity\n",
    "                        ax.quiver(np.array([lon_buoy]), np.array([lat_buoy]), \n",
    "                                  *fix_cartopy_vectors(u.magnitude,v.magnitude,np.array([lat_buoy])), \n",
    "                                  scale=300, alpha=0.75, width=0.001, color=COL, \n",
    "                                  edgecolor=COL, lw=0.5, transform=ccrs.PlateCarree(), zorder=2)\n",
    "\n",
    "\n",
    "        #======================\n",
    "        # ADD WINDS\n",
    "        #======================\n",
    "        # check whether to import wind data\n",
    "        if ECMWF_winds != None:\n",
    "\n",
    "            # IMPORT WINDS\n",
    "            #=============\n",
    "            # grab nearest date index from ECMWF_winds file\n",
    "            rounded_date = ImageDate-datetime.timedelta(minutes = ImageDate.minute)\n",
    "            if not quiet:\n",
    "                print('Add wind data: nearest date ECMWF_winds --> {}'.format(rounded_date))\n",
    "            ds_winds = xr.open_dataset(ECMWF_winds).sel(time=rounded_date)\n",
    "            ds_winds.close()\n",
    "            u10  = ds_winds.u10.values\n",
    "            v10  = ds_winds.v10.values\n",
    "            lat = ds_winds.latitude.values\n",
    "            lon = ds_winds.longitude.values\n",
    "            Lons, Lats = np.meshgrid(lon, lat)\n",
    "\n",
    "            # PLOT\n",
    "            #=====\n",
    "            # fix vectors for cartopy plotting (only for plotting!!!)\n",
    "            add_vectors(fig, ax, Lons, Lats, u10, v10, regrid=[5], color=(0, 0, 0), scale=150, \n",
    "                        width=0.006, headwidth=3, headaxislength=4, headlength=4, minshaft=1, minlength=1, \n",
    "                        linewidth=0, alpha=0.2, angles='uv', pivot='mid', zorder_winds=7,\n",
    "                        quiv_key=None)\n",
    "\n",
    "#             # streamline intersecting PB\n",
    "#             c = ax.streamplot(Lons, Lats, *fix_cartopy_vectors(u10,v10,Lats), \n",
    "#                               start_points=[map_projection.transform_point(205,71.5, src_crs=ccrs.PlateCarree())],\n",
    "#                               integration_direction = 'backward', \n",
    "#                               arrowstyle='-',\n",
    "#                               color='red',transform=ccrs.PlateCarree(), linewidth=3, zorder=2)\n",
    "#             c.lines.set_alpha(0.3)\n",
    "\n",
    "\n",
    "\n",
    "        #======================\n",
    "        # ADD MSLP\n",
    "        #======================\n",
    "        # check whether to import wind data\n",
    "        if ECMWF_mslp != None:\n",
    "\n",
    "            # IMPORT MSLP\n",
    "            #=============\n",
    "            # grab nearest date index from ECMWF_mslp file\n",
    "            rounded_date = ImageDate-datetime.timedelta(minutes = ImageDate.minute)\n",
    "            if not quiet:\n",
    "                print('Add msl data: nearest date ECMWF_mslp --> {}'.format(rounded_date))\n",
    "            ds_mslp = xr.open_dataset(ECMWF_mslp).sel(time=rounded_date)\n",
    "            ds_mslp.close()\n",
    "            msl  = ds_mslp.msl.values/100\n",
    "            lat = ds_mslp.latitude.values\n",
    "            lon = ds_mslp.longitude.values\n",
    "            Lons, Lats = np.meshgrid(lon, lat)\n",
    "\n",
    "            # PLOT MSLP\n",
    "            #==========\n",
    "    #         fig, ax = add_mslp(fig, ax, Lons, Lats, msl, \n",
    "    #                            MSLrange = [940, 1060], MSL_colorrange = [980,1005,1015,1040],\n",
    "    #                            ContSize = 4, linewidths = 1, cmap = 'RdBu', zorder = 8,bar_vshift=-0.015,\n",
    "    #                            save_stage = False, save_name = ImageName, suffix = '_mslp_wide')\n",
    "\n",
    "    #     plt.show()\n",
    "\n",
    "        fig.savefig(ImageName+'_v3.png',bbox_inches=\"tight\", pad_inches = 0, dpi=300)\n",
    "        fig.clear()\n",
    "        plt.close(fig) \n",
    "\n",
    "        print(ImageName)\n",
    "        \n",
    "    else:\n",
    "        print(f' - skipping {ImageName}')\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "print(f'>>> runtime: {datetime.datetime.now()-starttime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageName' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mImageName\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageName' is not defined"
     ]
    }
   ],
   "source": [
    "ImageName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs((time[0]-ImageDate).total_seconds())/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Timestamp('2021-04-17 23:10:00')], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Jewell_EasyStore/SIDEx2021/sidex_tracks/interpolated/OSU-IT-53_300534061988500_interp.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buoy_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_projection = ccrs.NorthPolarStereo(central_longitude=210)\n",
    "\n",
    "# # narrow around SIDEX camp\n",
    "# lon_range = [200, 230]   # specify lon range to plot\n",
    "# lat_range = [69.5,75]   # specify lat range to plot\n",
    "\n",
    "\n",
    "# lat_range = [70.5, 74.5]\n",
    "# lon_range = [202, 225]\n",
    "\n",
    "\n",
    "# medium range\n",
    "# lon_range = [195, 235]   # specify lon range to plot\n",
    "# lat_range = [68.5,78]   # specify lat range to plot\n",
    "# map_projection = ccrs.NorthPolarStereo(central_longitude=215)\n",
    "\n",
    "# wide range for weather overlay\n",
    "# lon_range = [175, 245]   # specify lon range to plot\n",
    "# lat_range = [66,89]   # specify lat range to plot\n",
    "\n",
    "\n",
    "# for masters presentation\n",
    "# v1\n",
    "# lon_range = [192.5, 232.5]   # specify lon range to plot\n",
    "# lat_range = [68.75,78]   # specify lat range to plot\n",
    "# wider\n",
    "# lon_range = [170, 245]   # specify lon range to plot\n",
    "# lat_range = [65,85]   # specify lat range to plot\n",
    "\n",
    "# map_projection\n",
    "#==============================================================\n",
    "# north polar stereographic\n",
    "# map_projection = ccrs.NorthPolarStereo(central_longitude=210)#ccrs.NorthPolarStereo(central_longitude=215)\n",
    "# bad projection kenzie is using:\n",
    "# map_projection = ccrs.PlateCarree(central_longitude=180)\n",
    "# below add: shading='nearest', to make plot\n",
    "#==============================================================\n",
    "# Albers_CCRS = ccrs.AlbersEqualArea(central_longitude=-154, central_latitude=50, \n",
    "#                                     false_easting=0.0, false_northing=0.0, \n",
    "#                                     standard_parallels=(55, 65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenvOSU",
   "language": "python",
   "name": "geoenvosu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
